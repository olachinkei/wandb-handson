"""
===========================================
ART-E Email Search Agent - ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
===========================================

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š
- ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
- Rolloutï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œï¼‰é–¢æ•°
- RULERè©•ä¾¡é–¢æ•°
- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—

ä½¿ã„æ–¹:
    # æœ¬ç•ªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    python art_e.py
    
    # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
    python art_e.py --demo
"""

import argparse
import asyncio
import json
import logging
import random
from dataclasses import asdict
from textwrap import dedent

import art
import weave
from art.rewards.ruler import ruler_score_group
from art.serverless.backend import ServerlessBackend
from art.utils import iterate_dataset
from art.utils.strip_logprobs import strip_logprobs
from dotenv import load_dotenv
from langchain_core.utils.function_calling import convert_to_openai_tool
from litellm import acompletion
from openai import AsyncOpenAI
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_exponential

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from config import Config, get_config
from utils import (
    FinalAnswer,
    Scenario,
    load_scenarios,
    read_email,
    search_emails,
)

# ===========================================
# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
# ===========================================
load_dotenv()

# Weaveã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’æŠ‘åˆ¶ï¼ˆæ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®æŠ‘åˆ¶ï¼‰
logging.getLogger("weave").setLevel(logging.CRITICAL)


# ===========================================
# RULERè©•ä¾¡ç”¨ãƒ¢ãƒ‡ãƒ«
# ===========================================

class CorrectnessJudgeResponse(BaseModel):
    """
    å›ç­”ã®æ­£ç¢ºæ€§ã‚’åˆ¤å®šã™ã‚‹LLMã‚¸ãƒ£ãƒƒã‚¸ã®å¿œç­”ãƒ¢ãƒ‡ãƒ«
    
    Attributes:
        reasoning: åˆ¤æ–­ã®ç†ç”±èª¬æ˜
        accept: å›ç­”ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹ã©ã†ã‹
    """
    reasoning: str = Field(description="åˆ¤æ–­ãƒ—ãƒ­ã‚»ã‚¹ã®èª¬æ˜")
    accept: bool = Field(description="AIå›ç­”ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹ã©ã†ã‹")


# ===========================================
# Trajectoryï¼ˆè»Œè·¡ï¼‰ã‚¯ãƒ©ã‚¹
# ===========================================

class ProjectTrajectory(art.Trajectory):
    """
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®Trajectoryã‚¯ãƒ©ã‚¹
    
    ARTã®Trajectoryã‚’æ‹¡å¼µã—ã€æœ€çµ‚å›ç­”ã‚’ä¿æŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚
    
    Attributes:
        final_answer: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¿”ã—ãŸæœ€çµ‚å›ç­”ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    final_answer: FinalAnswer | None = None


class EmailScenario(BaseModel):
    """
    ãƒ¡ãƒ¼ãƒ«ã‚·ãƒŠãƒªã‚ªã®ãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ‡ãƒ«
    
    Attributes:
        step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·
        scenario: ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿
    """
    step: int
    scenario: Scenario


# ===========================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å‚ç…§ï¼‰
# ===========================================
_config: Config = None


def get_current_config() -> Config:
    """ç¾åœ¨ã®è¨­å®šã‚’å–å¾—"""
    global _config
    if _config is None:
        _config = get_config()
    return _config


def set_config(config: Config):
    """è¨­å®šã‚’ã‚»ãƒƒãƒˆ"""
    global _config
    _config = config


# ===========================================
# RULERè©•ä¾¡é–¢æ•°
# ===========================================

@weave.op  # Weaveã§ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¨˜éŒ²
@retry(stop=stop_after_attempt(3))
async def judge_correctness(
    scenario: Scenario, answer: str
) -> CorrectnessJudgeResponse:
    """
    LLMã‚¸ãƒ£ãƒƒã‚¸ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡
    
    RULERæ‰‹æ³•ã®ä¸€éƒ¨ã¨ã—ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”ãŒå‚ç…§å›ç­”ã¨ä¸€è‡´ã™ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    
    Args:
        scenario: è©•ä¾¡å¯¾è±¡ã®ã‚·ãƒŠãƒªã‚ª
        answer: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç”Ÿæˆã—ãŸå›ç­”
    
    Returns:
        CorrectnessJudgeResponse: åˆ¤å®šçµæœï¼ˆreasoning ã¨ acceptï¼‰
    """
    config = get_current_config()
    
    system_prompt = dedent(
        """
        ã‚ãªãŸã«ã¯è³ªå•ã€å‚ç…§å›ç­”ï¼ˆ**Reference answer**ï¼‰ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒç”Ÿæˆã—ãŸå›ç­”ï¼ˆ**AI answer**ï¼‰ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚

        ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã¯ã€AIå›ç­”ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã“ã¨ã§ã™ã€‚AIå›ç­”ã«å‚ç…§å›ç­”ã‹ã‚‰ã®é–¢é€£æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã®å›ç­”ã‚’å—ã‘å…¥ã‚Œã¦ãã ã•ã„ã€‚è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã€ã¾ãŸã¯å‚ç…§å›ç­”ã¨çŸ›ç›¾ã™ã‚‹å ´åˆã¯ã€å›ç­”ã‚’å—ã‘å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚
        """
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": (
                f"Question: {scenario.question}\n"
                f"Reference answer: {scenario.answer}\n"
                f"AI answer: {answer}"
            ),
        },
    ]

    # è¨­å®šã‹ã‚‰æ­£ç¢ºæ€§åˆ¤å®šãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    response = await acompletion(
        model=config.ruler.correctness_judge_model,
        messages=messages,
        response_format=CorrectnessJudgeResponse,
    )

    first_choice = response.choices[0]
    raw_content = first_choice.message.content or "{}"

    try:
        return CorrectnessJudgeResponse.model_validate_json(raw_content)
    except Exception as e:
        return CorrectnessJudgeResponse(
            reasoning=f"ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\nç”Ÿãƒ‡ãƒ¼ã‚¿: {raw_content}", accept=False
        )


# ===========================================
# Rollouté–¢æ•°
# ===========================================

@weave.op
async def rollout(model: art.Model, email_scenario: EmailScenario) -> ProjectTrajectory:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼ˆ1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å®Ÿè¡Œï¼‰
    
    ã“ã®é–¢æ•°ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š
    1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã‚·ãƒŠãƒªã‚ªã‚’æç¤º
    2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢
    3. æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
    4. RULERè©•ä¾¡ã§æ­£ç¢ºæ€§ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    
    Args:
        model: ä½¿ç”¨ã™ã‚‹ARTãƒ¢ãƒ‡ãƒ«
        email_scenario: å®Ÿè¡Œã™ã‚‹ã‚·ãƒŠãƒªã‚ª
    
    Returns:
        ProjectTrajectory: å®Ÿè¡Œè»Œè·¡ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã€å ±é…¬ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹å«ã‚€ï¼‰
    """
    config = get_current_config()
    scenario = email_scenario.scenario
    max_turns = config.training.max_turns

    # Trajectoryã®åˆæœŸåŒ–
    traj = ProjectTrajectory(
        reward=0.0,
        messages_and_choices=[],
        metadata={
            "scenario_id": scenario.id,
            "step": email_scenario.step,
        },
    )

    # ===========================================
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
    # ===========================================
    system_prompt = dedent(
        f"""
        ã‚ãªãŸã¯ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢ã—ã€ã‚¯ã‚¨ãƒªã¸ã®å›ç­”ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚å›ç­”ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«æœ€å¤§{max_turns}ã‚¿ãƒ¼ãƒ³ã¾ã§ä½¿ç”¨ã§ãã‚‹ã®ã§ã€æœ€åˆã®æ¤œç´¢ã§å›ç­”ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ç•°ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å†è©¦è¡Œã§ãã¾ã™ã€‚

        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: {scenario.inbox_address}
        ä»Šæ—¥ã®æ—¥ä»˜: {scenario.query_date}
        """
    )

    traj.messages_and_choices = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": scenario.question},
    ]

    # ===========================================
    # ãƒ„ãƒ¼ãƒ«å®šç¾©
    # ===========================================
    
    def search_inbox(keywords: list[str]) -> list[dict]:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œç´¢
        
        Args:
            keywords: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            list[dict]: æ¤œç´¢çµæœã®è¾æ›¸ãƒªã‚¹ãƒˆ
        """
        results = search_emails(
            inbox=scenario.inbox_address,
            keywords=keywords,
            sent_before=scenario.query_date,
        )
        return [asdict(result) for result in results]

    def return_final_answer(
        answer: str, reference_message_ids: list[str]
    ) -> FinalAnswer:
        """
        æœ€çµ‚å›ç­”ã¨å‚ç…§ãƒ¡ãƒ¼ãƒ«IDã‚’è¿”ã™
        
        Args:
            answer: å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
            reference_message_ids: å›ç­”ç”Ÿæˆã«ä½¿ç”¨ã—ãŸãƒ¡ãƒ¼ãƒ«ID
        
        Returns:
            FinalAnswer: æœ€çµ‚å›ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        return FinalAnswer(answer=answer, source_ids=reference_message_ids)

    # ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆã¨ãƒãƒƒãƒ”ãƒ³ã‚°
    tools = [search_inbox, read_email, return_final_answer]
    tools_by_name = {t.__name__: t for t in tools}
    traj.tools = [convert_to_openai_tool(t) for t in tools]

    # ===========================================
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
    # ===========================================
    client = AsyncOpenAI(
        base_url=model.inference_base_url,
        api_key=model.inference_api_key,
    )

    # ===========================================
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
    # ===========================================
    for _ in range(max_turns):
        # ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—
        response = await client.chat.completions.create(
            model=model.get_inference_name(),
            temperature=1,
            messages=traj.messages(),
            tools=traj.tools,
        )

        response_message = response.choices[0].message
        traj.messages_and_choices.append(response.choices[0])

        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã‘ã‚Œã°çµ‚äº†
        if not response_message.tool_calls:
            return traj

        try:
            # å„ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œ
            for tool_call in response_message.tool_calls:
                tool_name: str = tool_call.function.name
                if tool_name in tools_by_name:
                    tool_args = json.loads(tool_call.function.arguments)
                    tool_to_call = tools_by_name[tool_name]
                    result = tool_to_call(**tool_args)
                    
                    # ãƒ„ãƒ¼ãƒ«çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                    traj.messages_and_choices.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": str(result),
                        }
                    )

                    # æœ€çµ‚å›ç­”ã®å ´åˆã¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
                    if tool_name == "return_final_answer":
                        traj.final_answer = result
                        if traj.final_answer:
                            # RULERè©•ä¾¡ã‚’å®Ÿè¡Œ
                            correctness_judge_response = await judge_correctness(
                                scenario, traj.final_answer.answer
                            )
                            traj.metrics["correct"] = float(
                                correctness_judge_response.accept
                            )
                        return traj
        except Exception as e:
            print(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return traj

    return traj


# ===========================================
# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–é–¢æ•°
# ===========================================

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=2, min=10, max=120),
    reraise=True,
)
async def _register_model_with_retry(model: art.TrainableModel, backend: ServerlessBackend):
    """
    ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²
    
    W&Bã‚µãƒ¼ãƒãƒ¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€
    æœ€å¤§5å›ã€æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚
    """
    print("  ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ç™»éŒ²ä¸­...")
    await model.register(backend)
    print("  âœ… ãƒ¢ãƒ‡ãƒ«ç™»éŒ²å®Œäº†")


async def initialize_model(config: Config) -> art.TrainableModel:
    """
    ARTãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ã‚µãƒ¼ãƒãƒ¬ã‚¹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ç™»éŒ²
    
    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    
    Returns:
        art.TrainableModel: åˆæœŸåŒ–æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«
    """
    # å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰è¨­å®š
    if config.dataset.seed is not None:
        random.seed(config.dataset.seed)

    # ãƒ¢ãƒ‡ãƒ«ã®å®£è¨€
    model = art.TrainableModel(
        name=config.model.name,
        project=config.model.project,
        base_model=config.model.base_model,
    )

    # ã‚µãƒ¼ãƒãƒ¬ã‚¹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®åˆæœŸåŒ–
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã¯Weights & Biasesã‚µãƒ¼ãƒãƒ¼ã§å®Ÿè¡Œ
    backend = ServerlessBackend()

    # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ç™»éŒ²ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
    try:
        await _register_model_with_retry(model, backend)
    except Exception as e:
        print(f"\nâŒ ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print("\nğŸ’¡ å¯¾å‡¦æ³•:")
        print("  1. æ•°åˆ†å¾…ã£ã¦å†å®Ÿè¡Œ")
        print("  2. Google Colabã§å®Ÿè¡Œ")
        print("  3. W&Bã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª: https://status.wandb.ai/")
        raise

    return model


# ===========================================
# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
# ===========================================

async def train(config: Config):
    """
    ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
    
    GRPOã¨RULERã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
    
    å‡¦ç†ã®æµã‚Œ:
    1. å„ã‚¹ãƒ†ãƒƒãƒ—ã§è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿè¡Œ
    2. RULERã§å„è»Œè·¡ã«ç›¸å¯¾ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸
    3. GRPOã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
    4. å®šæœŸçš„ã«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    
    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ===========================================
    # è¨­å®šã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ã‚»ãƒƒãƒˆï¼ˆrollouté–¢æ•°ã‹ã‚‰å‚ç…§ï¼‰
    # ===========================================
    set_config(config)
    
    # ===========================================
    # Weaveã®åˆæœŸåŒ–
    # ===========================================
    weave.init(
        config.model.project,
        settings={"print_call_link": False},
        global_postprocess_output=strip_logprobs
    )
    
    # ===========================================
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    # ===========================================
    print("=" * 60)
    print("ART-E Email Search Agent - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
    print("=" * 60)
    print()
    print("ã€è¨­å®šã€‘")
    print(f"  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {config.model.project}")
    print(f"  ãƒ¢ãƒ‡ãƒ«å: {config.model.name}")
    print(f"  ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {config.model.base_model}")
    print()
    print("ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘")
    print(f"  groups_per_step: {config.training.groups_per_step}")
    print(f"  rollouts_per_group: {config.training.rollouts_per_group}")
    print(f"  num_epochs: {config.training.num_epochs}")
    print(f"  learning_rate: {config.training.learning_rate}")
    print(f"  max_steps: {config.training.max_steps}")
    print(f"  validation_step_interval: {config.training.validation_step_interval}")
    print()
    print("ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‘")
    print(f"  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ãƒŠãƒªã‚ªæ•°: {config.dataset.train_limit}")
    print(f"  ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒŠãƒªã‚ªæ•°: {config.dataset.val_limit}")
    print()
    
    model = await initialize_model(config)
    
    # ===========================================
    # ã‚·ãƒŠãƒªã‚ªã®èª­ã¿è¾¼ã¿
    # ===========================================
    print("ã‚·ãƒŠãƒªã‚ªã‚’èª­ã¿è¾¼ã¿ä¸­...")
    training_scenarios = load_scenarios(
        split="train",
        limit=config.dataset.train_limit,
        max_messages=config.dataset.max_messages,
        shuffle=config.dataset.shuffle,
        seed=config.dataset.seed,
    )
    
    validation_scenarios = load_scenarios(
        split="test",
        limit=config.dataset.val_limit,
        max_messages=config.dataset.max_messages,
        shuffle=config.dataset.shuffle,
        seed=config.dataset.seed,
    )
    
    print(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ãƒŠãƒªã‚ª: {len(training_scenarios)} ä»¶")
    print(f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒŠãƒªã‚ª: {len(validation_scenarios)} ä»¶")
    print()
    
    # ===========================================
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã®è¨­å®š
    # ===========================================
    training_iterator = iterate_dataset(
        training_scenarios,
        groups_per_step=config.training.groups_per_step,
        num_epochs=config.training.num_epochs,
        initial_step=await model.get_step(),
    )
    
    # ===========================================
    # ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
    # ===========================================
    print("=" * 60)
    print("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—é–‹å§‹")
    print("=" * 60)
    print()
    
    for batch in training_iterator:
        print(f"\n{'='*60}")
        print(f"ã‚¹ãƒ†ãƒƒãƒ— {batch.step} | ã‚¨ãƒãƒƒã‚¯ {batch.epoch} | ã‚¨ãƒãƒƒã‚¯å†…ã‚¹ãƒ†ãƒƒãƒ— {batch.epoch_step}")
        print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {len(batch.items)} ã‚·ãƒŠãƒªã‚ª")
        print(f"{'='*60}")
        
        # ===========================================
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ
        # ===========================================
        train_groups = []
        for scenario in batch.items:
            # å„ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’ç”Ÿæˆ
            train_groups.append(
                art.TrajectoryGroup(
                    (
                        rollout(model, EmailScenario(step=batch.step, scenario=scenario))
                        for _ in range(config.training.rollouts_per_group)
                    )
                )
            )
        
        # ===========================================
        # ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®åé›†
        # ===========================================
        print(f"ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’åé›†ä¸­...")
        finished_train_groups = await art.gather_trajectory_groups(
            train_groups,
            pbar_desc="gather",
            max_exceptions=config.training.rollouts_per_group * len(batch.items),
        )
        
        # ===========================================
        # RULERã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
        # ===========================================
        print(f"RULERã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­...")
        judged_groups = []
        for i, group in enumerate(finished_train_groups):
            # RULERã‚’ä½¿ç”¨ã—ã¦å„è»Œè·¡ã«ç›¸å¯¾ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸
            # LLMã‚¸ãƒ£ãƒƒã‚¸ãŒä¸å®Œå…¨ãªå‡ºåŠ›ã‚’è¿”ã™ã“ã¨ãŒã‚ã‚‹ã®ã§ãƒªãƒˆãƒ©ã‚¤
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    judged_group = await ruler_score_group(
                        group,
                        config.ruler.judge_model,
                        debug=config.ruler.debug
                    )
                    judged_groups.append(judged_group)
                    break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                except ValueError as e:
                    if "scores" in str(e) and attempt < max_retries - 1:
                        print(f"  âš ï¸ RULERã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å¤±æ•— (ã‚°ãƒ«ãƒ¼ãƒ— {i+1}, è©¦è¡Œ {attempt+1}/{max_retries}): {e}")
                        print(f"  â†’ ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                        continue
                    else:
                        print(f"  âŒ RULERã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å¤±æ•— (ã‚°ãƒ«ãƒ¼ãƒ— {i+1}): {e}")
                        raise
        
        # ===========================================
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæŒ‡å®šé–“éš”ã§å®Ÿè¡Œï¼‰
        # ===========================================
        if batch.step % config.training.validation_step_interval == 0:
            print(f"\nãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­ï¼ˆã‚¹ãƒ†ãƒƒãƒ— {batch.step}ï¼‰...")
            validation_groups = []
            for scenario in validation_scenarios:
                validation_groups.append(
                    art.TrajectoryGroup([
                        rollout(model, EmailScenario(step=batch.step, scenario=scenario))
                    ])
                )
            
            finished_validation_groups = await art.gather_trajectory_groups(
                validation_groups,
                pbar_desc="validation",
                max_exceptions=len(validation_scenarios),
            )
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ãƒ­ã‚°
            await model.log(
                finished_validation_groups,
                split="val"
            )
            print(f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
        
        # ===========================================
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        # ===========================================
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
        await model.delete_checkpoints()
        await model.train(
            judged_groups,
            config=art.TrainConfig(learning_rate=config.training.learning_rate),
        )
        
        print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ— {batch.step} å®Œäº†")
        
        # ===========================================
        # æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
        # ===========================================
        if batch.step >= config.training.max_steps:
            print(f"\næœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° ({config.training.max_steps}) ã«é”ã—ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†ã€‚")
            break
    
    print()
    print("=" * 60)
    print("ğŸ‰ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
    print("=" * 60)
    print()
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. W&B/Weaveãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèª")
    print("  2. python test_model.py ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ")


# ===========================================
# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
# ===========================================

def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="ART-E Email Search Agent ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"
    )
    
    parser.add_argument(
        "--demo",
        action="store_true",
        help="ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰"
    )
    
    parser.add_argument(
        "--project",
        type=str,
        default=None,
        help="Weave/W&Bãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--max-steps",
        type=int,
        default=None,
        help="æœ€å¤§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--groups-per-step",
        type=int,
        default=None,
        help="ã‚¹ãƒ†ãƒƒãƒ—ã‚ãŸã‚Šã®ã‚°ãƒ«ãƒ¼ãƒ—æ•°ã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--rollouts-per-group",
        type=int,
        default=None,
        help="ã‚°ãƒ«ãƒ¼ãƒ—ã‚ãŸã‚Šã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ•°ã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=None,
        help="å­¦ç¿’ç‡ã‚’ä¸Šæ›¸ã"
    )
    
    return parser.parse_args()


# ===========================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ===========================================

async def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    args = parse_args()
    
    # è¨­å®šã‚’å–å¾—ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹ã§åˆ‡ã‚Šæ›¿ãˆï¼‰
    config = get_config(use_demo=args.demo)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
    if args.project:
        config.model.project = args.project
    if args.max_steps:
        config.training.max_steps = args.max_steps
    if args.groups_per_step:
        config.training.groups_per_step = args.groups_per_step
    if args.rollouts_per_group:
        config.training.rollouts_per_group = args.rollouts_per_group
    if args.learning_rate:
        config.training.learning_rate = args.learning_rate
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    await train(config)


if __name__ == "__main__":
    asyncio.run(main())
