"""
===========================================
ART-E Email Search Agent - ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ (W&B Inference)
===========================================

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’W&B Inference APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
art_e.pyã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå¾Œã«ä½¿ç”¨ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    # åŸºæœ¬çš„ãªä½¿ç”¨æ³•ï¼ˆartifact_pathã¯å¿…é ˆï¼‰
    python test_model.py --artifact-path "wandb-artifact:///agent-lab/ARTE-Email-Search-Agent/email-agent-003:v160"
    
    # ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªæ•°ã§ãƒ†ã‚¹ãƒˆ
    python test_model.py --artifact-path "wandb-artifact:///..." --num-scenarios 10
    
    # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
    python test_model.py --artifact-path "wandb-artifact:///..." --demo
"""

import argparse
import asyncio
import json
import logging
import os
import random
from dataclasses import asdict
from textwrap import dedent

import openai
import weave
from dotenv import load_dotenv
from langchain_core.utils.function_calling import convert_to_openai_tool
from litellm import acompletion
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from config import Config, get_config
from utils import (
    FinalAnswer,
    Scenario,
    load_scenarios,
    read_email,
    search_emails,
)

# ===========================================
# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
# ===========================================
load_dotenv()

# Weaveã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’æŠ‘åˆ¶
logging.getLogger("weave").setLevel(logging.CRITICAL)


# ===========================================
# RULERè©•ä¾¡ç”¨ãƒ¢ãƒ‡ãƒ«
# ===========================================

class CorrectnessJudgeResponse(BaseModel):
    """
    å›ç­”ã®æ­£ç¢ºæ€§ã‚’åˆ¤å®šã™ã‚‹LLMã‚¸ãƒ£ãƒƒã‚¸ã®å¿œç­”ãƒ¢ãƒ‡ãƒ«
    """
    reasoning: str = Field(description="åˆ¤æ–­ãƒ—ãƒ­ã‚»ã‚¹ã®èª¬æ˜")
    accept: bool = Field(description="AIå›ç­”ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹ã©ã†ã‹")


# ===========================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
# ===========================================
_config: Config = None


def get_current_config() -> Config:
    """ç¾åœ¨ã®è¨­å®šã‚’å–å¾—"""
    global _config
    if _config is None:
        _config = get_config()
    return _config


def set_config(config: Config):
    """è¨­å®šã‚’ã‚»ãƒƒãƒˆ"""
    global _config
    _config = config


# ===========================================
# RULERè©•ä¾¡é–¢æ•°
# ===========================================

@weave.op
@retry(stop=stop_after_attempt(3))
async def judge_correctness(
    scenario: Scenario, answer: str
) -> CorrectnessJudgeResponse:
    """
    LLMã‚¸ãƒ£ãƒƒã‚¸ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡
    """
    config = get_current_config()
    
    system_prompt = dedent(
        """
        ã‚ãªãŸã«ã¯è³ªå•ã€å‚ç…§å›ç­”ï¼ˆ**Reference answer**ï¼‰ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒç”Ÿæˆã—ãŸå›ç­”ï¼ˆ**AI answer**ï¼‰ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚

        ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã¯ã€AIå›ç­”ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã“ã¨ã§ã™ã€‚AIå›ç­”ã«å‚ç…§å›ç­”ã‹ã‚‰ã®é–¢é€£æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã®å›ç­”ã‚’å—ã‘å…¥ã‚Œã¦ãã ã•ã„ã€‚è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã€ã¾ãŸã¯å‚ç…§å›ç­”ã¨çŸ›ç›¾ã™ã‚‹å ´åˆã¯ã€å›ç­”ã‚’å—ã‘å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚
        """
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": (
                f"Question: {scenario.question}\n"
                f"Reference answer: {scenario.answer}\n"
                f"AI answer: {answer}"
            ),
        },
    ]

    response = await acompletion(
        model=config.ruler.correctness_judge_model,
        messages=messages,
        response_format=CorrectnessJudgeResponse,
    )

    first_choice = response.choices[0]
    raw_content = first_choice.message.content or "{}"

    try:
        return CorrectnessJudgeResponse.model_validate_json(raw_content)
    except Exception as e:
        return CorrectnessJudgeResponse(
            reasoning=f"ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\nç”Ÿãƒ‡ãƒ¼ã‚¿: {raw_content}", accept=False
        )


# ===========================================
# ãƒ†ã‚¹ãƒˆçµæœã‚¯ãƒ©ã‚¹
# ===========================================

class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿æŒã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.messages = []
        self.final_answer: FinalAnswer | None = None
        self.metrics = {}
        self.tools = []


# ===========================================
# ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆé–¢æ•°ï¼ˆW&B Inferenceä½¿ç”¨ï¼‰
# ===========================================

@weave.op
async def rollout_test(
    client: openai.OpenAI,
    artifact_path: str,
    scenario: Scenario,
    config: Config,
) -> TestResult:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼ˆ1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å®Ÿè¡Œï¼‰
    
    W&B Inference APIã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    
    Args:
        client: OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆW&B Inferenceç”¨ï¼‰
        artifact_path: W&Bã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‘ã‚¹
        scenario: å®Ÿè¡Œã™ã‚‹ã‚·ãƒŠãƒªã‚ª
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    
    Returns:
        TestResult: å®Ÿè¡Œçµæœ
    """
    max_turns = config.training.max_turns
    result = TestResult()

    # ===========================================
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
    # ===========================================
    system_prompt = dedent(
        f"""
        ã‚ãªãŸã¯ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢ã—ã€ã‚¯ã‚¨ãƒªã¸ã®å›ç­”ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚å›ç­”ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«æœ€å¤§{max_turns}ã‚¿ãƒ¼ãƒ³ã¾ã§ä½¿ç”¨ã§ãã‚‹ã®ã§ã€æœ€åˆã®æ¤œç´¢ã§å›ç­”ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ç•°ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å†è©¦è¡Œã§ãã¾ã™ã€‚

        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: {scenario.inbox_address}
        ä»Šæ—¥ã®æ—¥ä»˜: {scenario.query_date}
        """
    )

    result.messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": scenario.question},
    ]

    # ===========================================
    # ãƒ„ãƒ¼ãƒ«å®šç¾©
    # ===========================================
    
    def search_inbox(keywords: list[str]) -> list[dict]:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œç´¢
        
        Args:
            keywords: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            list[dict]: æ¤œç´¢çµæœã®è¾æ›¸ãƒªã‚¹ãƒˆ
        """
        results = search_emails(
            inbox=scenario.inbox_address,
            keywords=keywords,
            sent_before=scenario.query_date,
        )
        return [asdict(result) for result in results]

    def return_final_answer(
        answer: str, reference_message_ids: list[str]
    ) -> FinalAnswer:
        """
        æœ€çµ‚å›ç­”ã¨å‚ç…§ãƒ¡ãƒ¼ãƒ«IDã‚’è¿”ã™
        
        Args:
            answer: å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
            reference_message_ids: å›ç­”ç”Ÿæˆã«ä½¿ç”¨ã—ãŸãƒ¡ãƒ¼ãƒ«ID
        
        Returns:
            FinalAnswer: æœ€çµ‚å›ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        return FinalAnswer(answer=answer, source_ids=reference_message_ids)

    # ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆã¨ãƒãƒƒãƒ”ãƒ³ã‚°
    tools = [search_inbox, read_email, return_final_answer]
    tools_by_name = {t.__name__: t for t in tools}
    result.tools = [convert_to_openai_tool(t) for t in tools]

    # ===========================================
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
    # ===========================================
    for _ in range(max_turns):
        # ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—
        response = client.chat.completions.create(
            model=artifact_path,
            temperature=1,
            messages=result.messages,
            tools=result.tools,
        )

        response_message = response.choices[0].message
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¾æ›¸å½¢å¼ã§ä¿å­˜
        assistant_msg = {
            "role": "assistant",
            "content": response_message.content or "",
        }
        if response_message.tool_calls:
            assistant_msg["tool_calls"] = [
                {
                    "id": tc.id,
                    "type": "function",
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments,
                    }
                }
                for tc in response_message.tool_calls
            ]
        result.messages.append(assistant_msg)

        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã‘ã‚Œã°çµ‚äº†
        if not response_message.tool_calls:
            return result

        try:
            # å„ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œ
            for tool_call in response_message.tool_calls:
                tool_name: str = tool_call.function.name
                if tool_name in tools_by_name:
                    tool_args = json.loads(tool_call.function.arguments)
                    tool_to_call = tools_by_name[tool_name]
                    tool_result = tool_to_call(**tool_args)
                    
                    # ãƒ„ãƒ¼ãƒ«çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                    result.messages.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": str(tool_result),
                        }
                    )

                    # æœ€çµ‚å›ç­”ã®å ´åˆã¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
                    if tool_name == "return_final_answer":
                        result.final_answer = tool_result
                        if result.final_answer:
                            # RULERè©•ä¾¡ã‚’å®Ÿè¡Œ
                            correctness_judge_response = await judge_correctness(
                                scenario, result.final_answer.answer
                            )
                            result.metrics["correct"] = float(
                                correctness_judge_response.accept
                            )
                        return result
        except Exception as e:
            print(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return result

    return result


# ===========================================
# ãƒ†ã‚¹ãƒˆé–¢æ•°
# ===========================================

async def test_single_scenario(
    client: openai.OpenAI,
    artifact_path: str,
    scenario: Scenario,
    config: Config,
    step: int = 0
):
    """
    å˜ä¸€ã®ã‚·ãƒŠãƒªã‚ªã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
    """
    print(f"\n{'='*60}")
    print(f"ã‚·ãƒŠãƒªã‚ª ID: {scenario.id}")
    print(f"{'='*60}")
    print(f"è³ªå•: {scenario.question}")
    print(f"æœŸå¾…ã•ã‚Œã‚‹å›ç­”: {scenario.answer}")
    print(f"å‚ç…§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID: {scenario.message_ids}")
    print(f"ãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹: {scenario.inbox_address}")
    print(f"ã‚¯ã‚¨ãƒªæ—¥ä»˜: {scenario.query_date}")
    print("-" * 50)

    # ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Ÿè¡Œ
    result = await rollout_test(client, artifact_path, scenario, config)

    # çµæœã‚’è¡¨ç¤º
    print("\nã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è»Œè·¡ã€‘")
    print("-" * 40)

    for msg in result.messages:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        tool_calls = msg.get("tool_calls", [])

        if role == "system":
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯çŸ­ç¸®è¡¨ç¤º
            print(
                f"[SYSTEM]: {content[:100]}..."
                if len(content) > 100
                else f"[SYSTEM]: {content}"
            )
        elif role == "user":
            print(f"[USER]: {content}")
        elif role == "assistant":
            if tool_calls:
                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
                for tc in tool_calls:
                    if isinstance(tc, dict):
                        func = tc.get("function", {})
                        print(f"[ASSISTANT â†’ {func.get('name', '?')}]: {func.get('arguments', '{}')}")
                    else:
                        print(f"[ASSISTANT â†’ {tc.function.name}]: {tc.function.arguments}")
            if content:
                print(f"[ASSISTANT]: {content}")
        elif role == "tool":
            tool_name = msg.get("name", "unknown_tool")
            # ãƒ„ãƒ¼ãƒ«çµæœã¯çŸ­ç¸®è¡¨ç¤º
            print(
                f"[TOOL - {tool_name}]: {content[:200]}..."
                if len(content) > 200
                else f"[TOOL - {tool_name}]: {content}"
            )

        print()

    # æœ€çµ‚çµæœ
    print("-" * 50)
    print("\nã€çµæœã€‘")
    if result.final_answer:
        print(f"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”: {result.final_answer.answer}")
        print(f"   ä½¿ç”¨ã—ãŸã‚½ãƒ¼ã‚¹ID: {result.final_answer.source_ids}")
        
        # æ­£è§£åˆ¤å®š
        correct = result.metrics.get("correct", 0)
        if correct > 0:
            print(f"\nğŸ‰ æ­£è§£ï¼")
        else:
            print(f"\nâŒ ä¸æ­£è§£")
    else:
        print("âš ï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æœ€çµ‚å›ç­”ã‚’æä¾›ã—ã¾ã›ã‚“ã§ã—ãŸ")

    print(f"\nğŸ“ æœŸå¾…ã•ã‚Œã‚‹å›ç­”: {scenario.answer}")
    print(f"   æœŸå¾…ã•ã‚Œã‚‹ã‚½ãƒ¼ã‚¹ID: {scenario.message_ids}")
    
    return result


async def test_model(
    config: Config,
    artifact_path: str,
    num_scenarios: int = 5,
    api_key: str | None = None,
):
    """
    ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆï¼ˆW&B Inferenceä½¿ç”¨ï¼‰
    
    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        artifact_path: W&Bã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‘ã‚¹
        num_scenarios: ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚·ãƒŠãƒªã‚ªæ•°
        api_key: W&B APIã‚­ãƒ¼ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    """
    # ===========================================
    # è¨­å®šã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ã‚»ãƒƒãƒˆ
    # ===========================================
    set_config(config)
    
    # ===========================================
    # Weaveã®åˆæœŸåŒ–
    # ===========================================
    weave.init(
        config.model.project,
        settings={"print_call_link": False},
    )
    
    # ===========================================
    # APIã‚­ãƒ¼ã®å–å¾—
    # ===========================================
    if api_key is None:
        api_key = os.environ.get("WANDB_API_KEY") or os.environ.get("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError(
            "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            "ç’°å¢ƒå¤‰æ•° WANDB_API_KEY ã¾ãŸã¯ --api-key ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\n"
            "APIã‚­ãƒ¼ã¯ https://wandb.ai/authorize ã‹ã‚‰å–å¾—ã§ãã¾ã™ã€‚"
        )
    
    # ===========================================
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆW&B Inferenceç”¨ï¼‰
    # ===========================================
    client = openai.OpenAI(
        base_url="https://api.inference.wandb.ai/v1",
        api_key=api_key,
        # ä½¿ç”¨çŠ¶æ³ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç”¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
        default_headers={
            "X-Wandb-Project": config.model.project,
        }
    )
    
    # ===========================================
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
    # ===========================================
    print("=" * 60)
    print("ART-E Email Search Agent - ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ (W&B Inference)")
    print("=" * 60)
    print()
    print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {config.model.project}")
    print(f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‘ã‚¹: {artifact_path}")
    print(f"ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªæ•°: {num_scenarios}")
    print()
    
    # ===========================================
    # ã‚·ãƒŠãƒªã‚ªã®èª­ã¿è¾¼ã¿
    # ===========================================
    print("ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’èª­ã¿è¾¼ã¿ä¸­...")
    test_scenarios = load_scenarios(
        split="train",
        limit=num_scenarios,
        max_messages=config.dataset.max_messages,
        shuffle=config.dataset.shuffle,
        seed=config.dataset.seed,
    )
    
    print(f"èª­ã¿è¾¼ã‚“ã ã‚·ãƒŠãƒªã‚ªæ•°: {len(test_scenarios)}")
    
    # ===========================================
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    # ===========================================
    correct_count = 0
    total_count = 0
    
    for i, scenario in enumerate(test_scenarios):
        print(f"\n\n{'#'*60}")
        print(f"# ãƒ†ã‚¹ãƒˆ {i+1}/{len(test_scenarios)}")
        print(f"{'#'*60}")
        
        result = await test_single_scenario(
            client, artifact_path, scenario, config, step=i
        )
        
        total_count += 1
        if result.metrics.get("correct", 0) > 0:
            correct_count += 1
    
    # ===========================================
    # çµæœã‚µãƒãƒªãƒ¼
    # ===========================================
    print("\n")
    print("=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"æ­£è§£æ•°: {correct_count}/{total_count}")
    print(f"æ­£è§£ç‡: {correct_count/total_count*100:.1f}%")
    print()
    print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")


# ===========================================
# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
# ===========================================

def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="ART-E Email Search Agent ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ (W&B Inference)"
    )
    
    parser.add_argument(
        "--artifact-path",
        type=str,
        required=True,
        help=(
            "W&Bã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰\n"
            "ä¾‹: wandb-artifact:///agent-lab/ARTE-Email-Search-Agent/email-agent-003:v160"
        )
    )
    
    parser.add_argument(
        "--demo",
        action="store_true",
        help="ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰"
    )
    
    parser.add_argument(
        "--project",
        type=str,
        default=None,
        help="Weave/W&Bãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--num-scenarios",
        type=int,
        default=5,
        help="ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚·ãƒŠãƒªã‚ªæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=None,
        help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’ä¸Šæ›¸ã"
    )
    
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="W&B APIã‚­ãƒ¼ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•° WANDB_API_KEY ã‹ã‚‰å–å¾—ï¼‰"
    )
    
    return parser.parse_args()


# ===========================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ===========================================

async def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    args = parse_args()
    
    # è¨­å®šã‚’å–å¾—
    config = get_config(use_demo=args.demo)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
    if args.project:
        config.model.project = args.project
    if args.seed is not None:
        config.dataset.seed = args.seed
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    await test_model(
        config,
        artifact_path=args.artifact_path,
        num_scenarios=args.num_scenarios,
        api_key=args.api_key,
    )


if __name__ == "__main__":
    asyncio.run(main())
# python test_model.py --artifact-path "wandb-artifact:///agent-lab/ARTE-Email-Search-Agent/email-agent-003:v160" --num-scenarios 10
